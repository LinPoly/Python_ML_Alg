# Python_ML_Alg
## 1. Description

This is a repository containing **Programming Homework** of [**DS1003, NYU**](https://nyu-ds1003.github.io/spring2021/#resources).
I have worked on this course since May 2021 and there are still some homework I haven't finished yet.
So this repository is **still ongoing.**

Writing Homework of DS1003 is in [this repository](https://github.com/LinPoly/writing-homework).

## 2. Brief Introduction to Every Homework
### 2.1 Homework 1
(1) Fundamental mechanism of Numpy: Broadcasting and array operations.  
(2) Regularized Ridge Regression: Compute loss and implement gradient descent.  
(3) Gradient-based Optimization: SGD, Batch SGD and Gradient Checker.  

### 2.2 Homework 2
(1) Linear Lasso Regression: Run Lasso regression on a generated dataset.  
(2) Coordinate Descent for Lasso: Shooting Algorithm.  
(3) Homotopy Method: Warm starting for hyper-tuning.  
(4) Visualization: Sparsity on weight parameters of Lasso.  

### 2.3 Homework 3
(1) Data Processing: Dictionary representation of every movie review in [Polarity Dataset](https://www.cs.cornell.edu/people/pabo/movie-review-data/)  
(2) SVM for Sentiment Analysis: Train binary classification SVM on Polarity Dataset.  
(3) Implement Pegasos Algorithm: A subgradient descent method for SVM.  
(4) Error Analysis for Mis-classification: Weights of some neutral words are unreasonably big.  

### 2.4 Homework 4
(1) Kernel Function: Implement RBF kernel and polynomial kernel.  
(2) Kernelized Ridge Regression(KRR): Train KRR with different kernels.  
(3) Kernelized SVM: Visualize the dataset and Train SVM with different kernels.  
(4) Kernelize Pegasos: Implement Pegasos Algorithm for kernelized SVM.  

### 2.5 Homework 5  
(1) Logistic Regression: Implement logistic regression on a given dataset.  
(2) Bayesian Regression: Implement gaussian regression and plot the probabilistic distributions  

### 2.6 Homework 6
(1) Multiclass Classification: One-vs-all classification and class-sensitive mapping by SVM.  
(2) Decision Tree: Construct classfication decision tree and regression decision tree.  
(3) Gradient Boosting: Implement gradient boosting with l2 loss and decision tree.  

### 2.7 Homework 7
**Still ongoing...**
